# -*- coding: utf-8 -*-
"""
Created on Thu Aug  1 11:26:57 2019

@author: Evelyn
"""
# 2) Use basic kinematic equation as function
# 3) Initialize a value x from which to start the descent or optimization from (will I have to make one
# variable into a constant?)
# 4) Specify a learning rate that will determine how much of a step to descend by or how quickly you converge to the minimum value
# 5) Obtain the derivative of that value x (the descent) (or, partial derivatives here)
# 6) ///Proceed to descend by the derivative of that value multiplied by the learning rate///
# 7) Update the value of x with the new value descended to
# 8) Check your stop condition to see whether to stop
# 9) If condition satisfied, stop. If not, proceed to step 4 with the new x value and keep repeating algorithm